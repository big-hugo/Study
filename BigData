Hadoop
用于大数据分析的软件,由一个namenode和多个node节点组成

Hadoop的部署模式: 单机  伪分布式  完全分布式

单机模式搭建
安装hadoop
yum -y install java-1.8.0-openjdk-devel             安装jdk依赖包
jps                                                 查看jps验证
tar -xf hadoop-2.7.7.tar.gz                         解压Hadoop包
mv hadoop-2.7.7 /usr/local/hadoop                   移动解压后目录
rpm -ql java-1.8.0-openjdk                          查看java安装路径
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre
cd /usr/local/hadoop                                进入Hadoop主目录
vim ./etc/hadoop/hadoop-env.sh                      编辑启动脚本
25 export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre"  写入jdk路径
33 export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"  写入配置文件路径
/usr/local/hadoop/bin/hadoop                        现在可以启动脚本
mkdir /usr/local/hadoop/input                       新建文件夹
cp *.txt /usr/local/hadoop/input                    复制说明书到文件夹
./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount input output   开始大数据分析
 //wordcount为参数 统计input这个文件夹，存到output这个文件里面（这个文件不能存在，要是存在会报错，是为了防止数据覆盖

完全分布式搭建
环境: namenode 1台   node 3台
yum install -y java-1.8.0-openjdk-devel              安装jdk依赖包(所有机子都要装)
vim /etc/hosts                                       域名解析互通(所有机子可以互相解析)
jps                                                  查看jps验证
vim /etc/ssh/ssh_config                              修改配置文件(namedone需要免密连接所有节点包括本机)
60         StrictHostKeyChecking no                  本机免密登录
ssh-keygen                                           生产秘钥(一路回车)
for i in node1 node2 node3; do ssh-copy-id 192.168.1.$i; done     发送公钥给节点
tar -xf hadoop-2.7.7.tar.gz                         解压Hadoop包
mv hadoop-2.7.7 /usr/local/hadoop                   移动解压后目录
rpm -ql java-1.8.0-openjdk                          查看java安装路径
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre
cd /usr/local/hadoop                                进入Hadoop主目录
vim ./etc/hadoop/hadoop-env.sh                      编辑启动脚本
25 export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre"  写入jdk路径
33 export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"  写入配置文件路径
vim /usr/local/hadoop/etc/hadoop/core-site.xml      修改核心文件
<configuration>
<property>
        <name>fs.defaultFS</name>                   定义使用文件系统
        <value>hdfs://namenode:9000</value>          本机磁盘
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/hadoop</value>
    </property>
</configuration>
vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml
<configuration>
<property>
        <name>dfs.namenode.http-address</name>
        <value>namenode:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>namenode:50090</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
</configuration>
vim /usr/local/hadoop/etc/hadoop/slaves             输入节点主机名
node1
node2
node3
for i in node{1..3}; do rsync -aXSH --delete /usr/local/hadoop/ ${i}:/usr/local/ &; done   同步所有节点配置
mkdir /var/hadoop
/usr/local/hadoop/bin/hdfs namenode -format         //格式化 namenode
/usr/local/hadoop/sbin/start-dfs.sh                  启动服务
/usr/local/hadoop/sbin/stop-dfs.sh                   关闭服务
jps                                                  查看jps角色(namenode有三个为成功,其他节点有两个)
/usr/local/hadoop/bin/hdfs dfsadmin -report          查看集群角色










