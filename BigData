Hadoop
用于大数据分析的软件,由一个namenode和多个node节点组成

Hadoop的部署模式: 单机  伪分布式  完全分布式

单机模式搭建
安装hadoop
yum -y install java-1.8.0-openjdk-devel             安装jdk依赖包
jps                                                 查看jps验证
tar -xf hadoop-2.7.7.tar.gz                         解压Hadoop包
mv hadoop-2.7.7 /usr/local/hadoop                   移动解压后目录
rpm -ql java-1.8.0-openjdk                          查看java安装路径
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre
cd /usr/local/hadoop                                进入Hadoop主目录
vim ./etc/hadoop/hadoop-env.sh                      编辑启动脚本
25 export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre"  写入jdk路径
33 export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"  写入配置文件路径
/usr/local/hadoop/bin/hadoop                        现在可以启动脚本
mkdir /usr/local/hadoop/input                       新建文件夹
cp *.txt /usr/local/hadoop/input                    复制说明书到文件夹
./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount input output   开始大数据分析
 //wordcount为参数 统计input这个文件夹，存到output这个文件里面（这个文件不能存在，要是存在会报错，是为了防止数据覆盖

完全分布式搭建
环境: namenode 1台   node 3台
yum install -y java-1.8.0-openjdk-devel              安装jdk依赖包(所有机子都要装)
vim /etc/hosts                                       域名解析互通(所有机子可以互相解析)
jps                                                  查看jps验证
vim /etc/ssh/ssh_config                              修改配置文件(namedone需要免密连接所有节点包括本机)
60         StrictHostKeyChecking no                  本机免密登录
ssh-keygen                                           生产秘钥(一路回车)
for i in node1 node2 node3; do ssh-copy-id 192.168.1.$i; done     发送公钥给节点
tar -xf hadoop-2.7.7.tar.gz                         解压Hadoop包
mv hadoop-2.7.7 /usr/local/hadoop                   移动解压后目录
rpm -ql java-1.8.0-openjdk                          查看java安装路径
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre
cd /usr/local/hadoop                                进入Hadoop主目录
vim ./etc/hadoop/hadoop-env.sh                      编辑启动脚本
25 export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre"  写入jdk路径
33 export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"  写入配置文件路径
vim /usr/local/hadoop/etc/hadoop/core-site.xml      修改核心文件
<configuration>
<property>
        <name>fs.defaultFS</name>                   定义使用文件系统
        <value>hdfs://namenode:9000</value>         本机磁盘,namenode为主节点名
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/hadoop</value>
    </property>
</configuration>
vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml
<configuration>
<property>
        <name>dfs.namenode.http-address</name>
        <value>namenode:50070</value>                namenode为主节点名
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>namenode:50090</value>                 namenode为主节点名
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
</configuration>
vim /usr/local/hadoop/etc/hadoop/slaves             输入节点主机名
node1
node2
node3
for i in node{1..3}; do rsync -aXSH --delete /usr/local/hadoop/ ${i}:/usr/local/ &; done   同步所有节点配置
mkdir /var/hadoop
/usr/local/hadoop/bin/hdfs namenode -format         //格式化 namenode
/usr/local/hadoop/sbin/start-dfs.sh                  启动服务
/usr/local/hadoop/sbin/stop-dfs.sh                   关闭服务
jps                                                  查看jps角色(namenode有三个为成功,其他节点有两个)
/usr/local/hadoop/bin/hdfs dfsadmin -report          查看集群角色
(启动不来可以删除其他节点上的/var/hadoop/*)

Mapreduce分布式计算框架部署
在namenode上操作,确保所有节点已完成完全分布式搭建
cd /usr/local/hadoop/etc/hadoop                      进入配置文件目录
mv mapred-site.xml.template mapred-site.xml          更改配置文件名字
vim mapred-site.xml                                  修改配置文件
<configuration>
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
vim yarn-site.xml                                    修改配置文件
<configuration>
<property>
        <name>yarn.resourcemanager.hostname</name>
        <value>namenode</value>                       namenode为主节点名
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
for i in node{1..3}; do rsync -aSH --delete /usr/local/hadoop/ $i:/usr/local/hadoop/  -e 'ssh' & done   同步配置文件到节点
/usr/local/hadoop/sbin/stop-dfs.sh                   关闭服务
/usr/local/hadoop/sbin/start-dfs.sh                  启动服务
/usr/local/hadoop/sbin/start-yarn.sh                 开启框架
 /usr/local/hadoop/bin/yarn node -list               查看节点
http://192.168.1.60:50070/            //--namenode web页面（namenod）
http://192.168.1.60:50090/        //--secondory namenode web页面（namenode）
http://192.168.1.61:50075/        //--datanode web页面（node1,node2,node3）
http://192.168.1.60:8088/        //--resourcemanager web页面（namenode）
http://192.168.1.61:8042/        //--nodemanager web页面（node1,node2,node3）

HDFS命令
cd /usr/local/hadoop
./bin/hadoop fs -ls /             查看集群文件系统的根，没有内容
./bin/hadoop fs -mkdir  /aaa      在集群文件系统下创建aaa目录
./bin/hadoop fs -touchz  /fa      在集群文件系统下创建fa文件
./bin/hadoop fs -put *.txt /aaa   上传当前目录*.txt到集群文件系统下的aaa目录
./bin/hadoop fs -ls /aaa          查看
./bin/hadoop fs -get  /aaa        下载集群文件系统的aaa目录
./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount /aaa /bbb    
//hadoop集群分析大数据，hadoop集群/aaa里的数据存到hadoop集群/bbb下,bbb不需要提前创建
./bin/hadoop fs -cat /bbb/*        查看集群里的数据

hadoop节点管理
添加节点node4
yum -y install java-1.8.0-openjdk-devel     安装软件,在node4上操作
vim /etc/hosts                              改域名解析,所有节点同步
ssh-copy-id node4                            发送公钥,namenode上操作
vim /usr/local/hadoop/etc/hadoop/slaves     输入节点主机名,,namenode上操作
...
node4
for i in node{1..4}; do rsync -aSH --delete /usr/local/hadoop/ $i:/usr/local/hadoop/  -e 'ssh' & done   同步配置文件到节点
/usr/local/hadoop/sbin/hadoop-daemon.sh start datanode  启动节点服务
/usr/local/hadoop/bin/hdfs dfsadmin -report             查看集群信息
/usr/local/hadoop/bin/hdfs dfsadmin -setBalancerBandwidth 60000000      在node4上设置同步带宽,防止多机器数据同步时卡死(600M)
/usr.local/hadoop/sbin/start-balancer.sh                启动自动同步数据服务
删除节点node4
vim /usr/local/hadoop/etc/hadoop/slaves       去掉之前添加的node4,namenode上操作
node1
node2
node3
vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml    在此配置文件里面加入下面四行,namenode上操作
<property>                                      
    <name>dfs.hosts.exclude</name>
    <value>/usr/local/hadoop/etc/hadoop/exclude</value>
</property>
vim /usr/local/hadoop/etc/hadoop/exclude       写入要删除的节点主机名,namenode上操作
node4
/usr/local/hadoop//bin/hdfs dfsadmin -refreshNodes      更新数据
/usr/local/hadoop/bin/hdfs dfsadmin -report             查看集群信息
Normal: 正常状态  Decommissioned in Program: 数据正在迁移    Decommissioned: 数据迁移完成才可以down机
退出yarn节点(在node4上操作)
./sbin/hadoop-daemon.sh stop datanode                   停止datanode
./sbin/yarn-daemon.sh start nodemanager                 yarn 增加 nodemanager
./sbin/yarn-daemon.sh stop  nodemanager  停止nodemanager
./bin/yarn node -list                                  yarn 查看节点状态，还是有node4节点，要过一段时间才会消失
jps                                                    显示只有一个角色

配置NFSGW
nfs网关用途: 用户可以从HDFS文件系统下载文档到本地文件系统
namenode和nfsgw上的代理用户UID,GID,用户名必须相同
namedone主机配置
vim /etc/hosts                   解析主机名(共享给所有节点)
groupadd -g 800 nfsuser          添加组,namenode和NFSGW共同操作
useradd -u 800 -g 800 -r -d /var/hadoop nfsuser     添加用户,namenode和NFSGW共同操作
./sbin/stop-all.sh               停止所有服务
vim /usr/local/hadoop/etc/hadoop/core-site.xml    加入以下配置
 <property>
        <name>hadoop.proxyuser.nfsuser.groups</name>   nfsuser为共同组名
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.nfsuser.hosts</name>    nfsuser为共同用户名
        <value>*</value>
    </property>
for i in {61..65}; do rsync -aSH --delete /usr/local/hadoop/ 192.168.1.$i:/usr/local/hadoop/  -e 'ssh' & done  同步到其他节点(提前做好密钥对)
/usr/local/hadoop/sbin/start-dfs.sh     启动集群
/usr/local/hadoop/bin/hdfs  dfsadmin -report         查看集群状态
准备nfsgw主机
yum -y install java-1.8.0-openjdk-devel     安装软件
rpm -qa | grep rpcbind           查看是否安装该软件,有就删除
rpm -qa | grep nfs               查看是否安装该软件,有就删除
vim /etc/hosts                   解析主机名
mkdir /var/hadoop                创建数据目录
groupadd -g 800 nfsuser          添加组,namenode和NFSGW共同操作
useradd -u 800 -g 800 -r -d /var/hadoop nfsuser     添加用户,namenode和NFSGW共同操作
mkdir /var/nfstmp                创建转储目录
chown nfsuser:nfsuser /var/nfstmp            给nfs用户授权
rm -rf  /usr/local/hadoop/logs/*             删除原有传过来的日志文件 
setfacl -m user:nfsuser:rwx /usr/local/hadoop/logs   给文件授权,不然写不进日志
vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml       修改配置文件
<property>
        <name>nfs.exports.allowed.hosts</name>
        <value>* rw</value>
    </property>
    <property>
        <name>nfs.dump.dir</name>
        <value>/var/nfstmp</value>
    </property>
/usr/local/hadoop/sbin/hadoop-daemon.sh --script ./bin/hdfs start portmap         portmap服务只能用root用户启动(如果要停止服务停下面的服务)
sudo -u nfsuser /usr/local/hadoop/sbin/hadoop-daemon.sh  --script ./bin/hdfs start nfs3    只能以nfsuser启动,只能用nfs3版本
jps                             root用户可以看到portmap和nfs3(普通用户只能看到两个)
现在,客户端可以挂载使用这部nfsgw主机
yum -y install nfs-utils      客户端安装nfs服务
mount -t nfs -o vers=3,proto=tcp,nolock,noatime,sync,noacl nfsgwIP地址:/  /mnt/    挂载
vim /etc/fstab            永久挂载
nfsgwIP地址:/  /mnt/ nfs  vers=3,proto=tcp,nolock,noatime,sync,noacl,_netdev 0 0 



Zookeeper
是一个开源的分布式应用程序协调服务,用来保证数据在集群间的事务一致性
角色与特性: Leader: 复制所有Follower进行内部数据交换
          Follower: 为客户端服务并参与提案投票,同时与Leader进行数据交换
          Observer:  为客户端服务但不参与提案投票,同时与Leader进行数据交换
角色与选举: 假如集群中拥有n台服务器,那么Leader必须得到n/2+1台服务器投票,剩下的是Follower
          Observer不计算在投票总设备数量里面,剩余机器不足n/2+1时,集群停止工作

Zookeeper安装
vim /etc/hosts                                      域名解析所有集群主机
tar -xf zookeeper-3.4.13.tar.gz                     解包
mv zookeeper-3.4.13 /usr/local/zookeeper            移动目录
cd /usr/local/zookeeper/conf/                       进入目录操作
mv zoo_sample.cfg  zoo.cfg                          重任命文件
chown root.root zoo.cfg                             授权
vim zoo.cfg                                         在文件后添加以下4行
server.1=node1:2888:3888                            node1.2.3为主机名
server.2=node2:2888:3888
server.3=node3:2888:3888
server.4=nn01:2888:3888:observer                     nn01为主机名
for i in node{1..3}; do scp -r /usr/local/zookeeper/ root@$i:/usr/local/zookeeper/; done   同步到其他节点
mkdir /tmp/zookeeper                                创建目录,每台主机都要
echo 4 >/tmp/zookeeper/myid                         创建 myid 文件，id 必须与配置文件里主机名对应的 server.(id) 一致
/usr/local/zookeeper/bin/zkServer.sh start          启动服务
/usr/local/zookeeper/bin/zkServer.sh status         查看集群状态
/usr/local/zookeeper/bin/zkServer.sh stop           关闭服务
yum -y install telnet                               安装控制软件
telnet node3 2181 
Trying 192.168.1.24...
Connected to node3.
Escape character is '^]'.
ruok                                          //发送
imokConnection closed by foreign host.        //imok回应的结果
 vim api.sh                                         查看api状态脚本
#!/bin/bash
function getstatus(){
    exec 9<>/dev/tcp/$1/2181 2>/dev/null
    echo stat >&9
    MODE=$(cat <&9 |grep -Po "(?<=Mode:).*")
    exec 9<&-
    echo ${MODE:-NULL}
}
for i in node{1..3} nn01;do
    echo -ne "${i}\t"
    getstatus ${i}
done


Kafka集群
是一个分布式的消息系统,消息中间件
[root@node1 hadoop]# tar -xf kafka_2.12-2.1.0.tgz
[root@node1 ~]# mv kafka_2.12-2.1.0 /usr/local/kafka
root@node1 ~]# cd /usr/local/kafka/config
[root@node1 config]# vim server.properties
broker.id=22
zookeeper.connect=node1:2181,node2:2181,node3:2181
拷贝 kafka 到其他主机，并修改 broker.id ,不能重复
[root@node1 config]# for i in 63 64; do rsync -aSH --delete /usr/local/kafka 192.168.1.$i:/usr/local/; done
[root@node2 ~]# vim /usr/local/kafka/config/server.properties   
broker.id=23
[root@node1 local]# /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties 
[root@node1 local]# jps        //出现kafka
验证配置，创建一个 topic
[root@node1 local]# /usr/local/kafka/bin/kafka-topics.sh --create --partitions 1 --replication-factor 1 --zookeeper node3:2181 --topic aa    
[root@node2 ~]# /usr/local/kafka/bin/kafka-console-producer.sh --broker-list node2:9092 --topic aa        //写一个数据,模拟生产者，发布消息
[root@node3 ~]# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic aa        //这边会直接同步,模拟消费者，接收消息
注意：kafka比较吃内存，做完这个kafka的实验可以把它停了












